{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwarlBEHGmGo"
      },
      "outputs": [],
      "source": [
        "# uploading data folders to google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DKCLKngVPQK7"
      },
      "outputs": [],
      "source": [
        "# reading files from drive\n",
        "import os\n",
        "import glob\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.signal as signal\n",
        "import matplotlib.pyplot as plt\n",
        "adhd_data_path = '/content/drive/MyDrive/Dataset_EEG/ADHD_part'\n",
        "control_data_path = '/content/drive/MyDrive/Dataset_EEG/Control_part'\n",
        "\n",
        "# list all the file paths in the specified folders\n",
        "adhd_data_file_paths = glob.glob(os.path.join(adhd_data_path, '*'))\n",
        "control_data_file_paths = glob.glob(os.path.join(control_data_path, '*'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oeqqALePQNx"
      },
      "outputs": [],
      "source": [
        "def data_array_createor(file_paths):\n",
        "    rows = []\n",
        "    # this for-loop is only to get all the rows\n",
        "    for file_path in file_paths:\n",
        "        content = scipy.io.loadmat(file_path)\n",
        "        keys = list(content.keys())\n",
        "        rows.append(content[keys[3]].shape[0])\n",
        "\n",
        "    rows.sort()\n",
        "    # since row numbers are varying, hence using the minimum row count\n",
        "    min_row_count = rows[0]\n",
        "    # creating empty numpy array\n",
        "    data_list = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        content = scipy.io.loadmat(file_path)\n",
        "        keys = list(content.keys())\n",
        "        data_list.append(content[keys[3]][0:min_row_count -1, 0:])\n",
        "\n",
        "    data_array = np.array(data_list)\n",
        "    return data_array\n",
        "\n",
        "adhd_data_array = data_array_createor(adhd_data_file_paths)\n",
        "print(adhd_data_array.shape)\n",
        "control_data_array = data_array_createor(control_data_file_paths)\n",
        "print(control_data_array.shape)\n",
        "\n",
        "# slicing adhd_data_array to make it of same dimension as control_data_array\n",
        "sliced_adhd_data_array = adhd_data_array[0:control_data_array.shape[0],0:control_data_array.shape[1], 0:]\n",
        "print(sliced_adhd_data_array.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IWZlGOWPhq2p"
      },
      "outputs": [],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z-qWHt7BiATt"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "def eeg_signal_plot(eeg_data, channel_name_list):\n",
        "\n",
        "    individuals, samples, channels = eeg_data.shape\n",
        "    sampling_rate = 128\n",
        "\n",
        "    # Define channel names and types\n",
        "    channel_names = channel_name_list\n",
        "    channel_types = ['eeg'] * channels\n",
        "\n",
        "    for i in range(individuals):\n",
        "    # Select data for the current patient\n",
        "        individual_data = eeg_data[i]\n",
        "\n",
        "    # Create MNE Info object\n",
        "        info = mne.create_info(ch_names=channel_names, sfreq=sampling_rate, ch_types=channel_types)\n",
        "\n",
        "    # Set a standard 10-20 montage\n",
        "        montage = mne.channels.make_standard_montage('standard_1020')\n",
        "        info.set_montage(montage)\n",
        "\n",
        "    # Create Raw object\n",
        "        # As MNE expects (channels, samples)\n",
        "        raw_data = mne.io.RawArray(individual_data.T, info)\n",
        "        raw_data.plot(scalings='auto')\n",
        "\n",
        "\n",
        "channel_seq = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2','F7','F8','T7','T8','P7','P8','Fz','Cz','Pz']\n",
        "eeg_signal_plot(sliced_adhd_data_array,channel_seq)\n",
        "eeg_signal_plot(control_data_array,channel_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GPnzpQ3aqWDy"
      },
      "outputs": [],
      "source": [
        "# FFT for calculating amplitude and frequency and plot them\n",
        "from scipy.fft import fft, fftfreq\n",
        "def apply_fft(eeg_data):\n",
        "    # calculates creates frequency bins and calculates amplitudes based on the positive cycles only\n",
        "    # Sampling rate (Hz)\n",
        "    fs = 128\n",
        "    # Apply FFT along the sample axis (axis=1)\n",
        "    eeg_data_fft = fft(eeg_data, axis=1)\n",
        "    # Get the corresponding frequency bins\n",
        "    freqs = fftfreq(eeg_data.shape[1], 1 / fs)\n",
        "    # Only keep the positive frequencies for and FFT coefficients corresponding to positive frequencies of ADHD\n",
        "    positive_freqs = freqs[:eeg_data.shape[1] // 2]\n",
        "    eeg_data_fft_positive = eeg_data_fft[:, :eeg_data.shape[1] // 2, :]\n",
        "    return positive_freqs, eeg_data_fft_positive\n",
        "\n",
        "positive_freqs_adhd, eeg_data_fft_positive_adhd = apply_fft(sliced_adhd_data_array)\n",
        "print('Frequency bins',positive_freqs_adhd)\n",
        "print('EEG data for positive cycles',eeg_data_fft_positive_adhd)\n",
        "positive_freqs_control, eeg_data_fft_positive_control = apply_fft(control_data_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AgaXFcbu0-lC"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.title('Control Data analysis in Frequency Domain')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Power')\n",
        "for i in range(eeg_data_fft_positive_control.shape[0]):\n",
        "    for j in range(eeg_data_fft_positive_control.shape[2]):\n",
        "        plt.plot(positive_freqs_control, np.abs(eeg_data_fft_positive_control[i,:,j]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwU4jfIT9V1s"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.title('ADHD Data analysis in Frequency Domain')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Power')\n",
        "for i in range(eeg_data_fft_positive_control.shape[0]):\n",
        "    for j in range(eeg_data_fft_positive_control.shape[2]):\n",
        "        plt.plot(positive_freqs_adhd, np.abs(eeg_data_fft_positive_adhd[i,:,j]))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xM2_IpnVqFll"
      },
      "outputs": [],
      "source": [
        "# implementing notch filter for removal of power line noise\n",
        "\n",
        "def power_line_noise_removal(eeg_data):\n",
        "    patients, samples, channels = eeg_data.shape\n",
        "    sampling_rate = 128\n",
        "\n",
        "    # Define channel names and types\n",
        "    channel_names = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2','F7','F8','T7','T8','P7','P8','Fz','Cz','Pz']\n",
        "    channel_types = ['eeg'] * channels\n",
        "\n",
        "    corrected_data_list = []\n",
        "\n",
        "    for i in range(patients):\n",
        "    # Select data for the current patient\n",
        "        patient_data = eeg_data[i]\n",
        "\n",
        "    # Create MNE Info object\n",
        "        info = mne.create_info(ch_names=channel_names, sfreq=sampling_rate, ch_types=channel_types)\n",
        "\n",
        "    # Create Raw object\n",
        "        raw_data = mne.io.RawArray(patient_data.T, info)  # As MNE expects (channels, samples)\n",
        "    # Adding a standard montage\n",
        "        montage = mne.channels.make_standard_montage('standard_1020')\n",
        "        raw_data.set_montage(montage)\n",
        "    # Apply the 50 Hz notch filter\n",
        "        raw_data.notch_filter(freqs=50, picks='eeg', filter_length='auto', phase='zero')\n",
        "\n",
        "        corrected_data_list.append(raw_data.get_data().T)  # Shape back to (n_samples, n_channels)\n",
        "    return np.array(corrected_data_list)\n",
        "\n",
        "corrected_adhd_data = power_line_noise_removal(sliced_adhd_data_array)\n",
        "corrected_control_data = power_line_noise_removal(control_data_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDg1XakVIBkW"
      },
      "outputs": [],
      "source": [
        "\n",
        "positive_freqs_adhd1, eeg_data_fft_positive_adhd1 = apply_fft(corrected_adhd_data)\n",
        "positive_freqs_control1, eeg_data_fft_positive_control1 = apply_fft(corrected_control_data)\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Control Data analysis in Frequency Domain')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Amplitude')\n",
        "for i in range(eeg_data_fft_positive_control1.shape[0]):\n",
        "    for j in range(eeg_data_fft_positive_control1.shape[2]):\n",
        "        plt.plot(positive_freqs_control1, np.abs(eeg_data_fft_positive_control1[i,:,j]))\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.title('ADHD Data analysis in Frequency Domain')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Amplitude')\n",
        "for i in range(eeg_data_fft_positive_adhd1.shape[0]):\n",
        "    for j in range(eeg_data_fft_positive_adhd1.shape[2]):\n",
        "        plt.plot(positive_freqs_adhd1, np.abs(eeg_data_fft_positive_adhd1[i,:,j]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5MyhRD9PQT2"
      },
      "outputs": [],
      "source": [
        "# Denoising the EEG signal using bandpass signal. It Removes baseline wander as well noise at slow frequency\n",
        "def bandpass_filter(data, low_cutoff, high_cutoff, sample_rate, order=8):\n",
        "   # bandpass_filter passes bands between low_cuffoff frequency and  high_cutoff frequency.\n",
        "\n",
        "# normalising the cutoff frequencies\n",
        "    nyquist = 0.5 * sample_rate  # Nyquist frequency\n",
        "    low = low_cutoff / nyquist\n",
        "    high = high_cutoff / nyquist\n",
        "    # it returns b and a for butterworth (IIR type - infinite impulse response) filter\n",
        "    b, a = signal.butter(order, [low, high], btype='bandpass', analog=False, output='ba')\n",
        "    # Apply the bandpass filter using filtfilt\n",
        "    filtered_signal = signal.filtfilt(b, a, data, padlen=18)  # Zero-phase filtering\n",
        "    return filtered_signal\n",
        "\n",
        "sample_rate = 128\n",
        "low_cutoff = 0.5  # Low cutoff frequency in Hz\n",
        "high_cutoff = 40  # High cutoff frequency in Hz\n",
        "order = 4\n",
        "filtered_ADHD_signal = bandpass_filter(corrected_adhd_data, low_cutoff, high_cutoff, sample_rate, order)\n",
        "print(filtered_ADHD_signal.shape)\n",
        "filtered_Control_signal = bandpass_filter(corrected_control_data, low_cutoff, high_cutoff, sample_rate, order)\n",
        "print(filtered_ADHD_signal.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCDNG8QkPQWY"
      },
      "outputs": [],
      "source": [
        "# Plot the original and Bandpass filtered ADHD signals\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "for i in range(corrected_adhd_data.shape[0]):\n",
        "    plt.plot(corrected_adhd_data[i])\n",
        "plt.title('Original ADHD Signal')\n",
        "plt.xlabel('Time in milli seconds')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "for i in range(filtered_ADHD_signal.shape[0]):\n",
        "    plt.plot(filtered_ADHD_signal[i])\n",
        "plt.title('Filtered ADHD Signal by Bandpass Filter')\n",
        "plt.xlabel('Time in milli seconds')\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVyxvPy4V41S"
      },
      "outputs": [],
      "source": [
        "# Plot the Original and Bandpass filtered Control signals\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "for i in range(corrected_control_data.shape[0]):\n",
        "    plt.plot(corrected_control_data[i])\n",
        "plt.title('Original Control Signal')\n",
        "plt.xlabel('Time in milli seconds')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "for i in range(filtered_Control_signal.shape[0]):\n",
        "    plt.plot(filtered_Control_signal[i])\n",
        "plt.title('Filtered Control Signal by Bandpass Filter')\n",
        "plt.xlabel('Time in milli seconds')\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QDbcDs7BDO_G"
      },
      "outputs": [],
      "source": [
        "# applying ICA from mne library to remove further artefacts\n",
        "import mne\n",
        "from mne.preprocessing import ICA\n",
        "def implement_ICA(eeg_data):\n",
        "    candidates, samples, channels = eeg_data.shape\n",
        "    sampling_rate = 128\n",
        "\n",
        "    # Define channel names and types\n",
        "    channel_names = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2','F7','F8','T7','T8','P7','P8','Fz','Cz','Pz']\n",
        "    channel_types = ['eeg'] * channels\n",
        "\n",
        "    ica_results = []\n",
        "    corrected_data_list = []\n",
        "\n",
        "    for i in range(candidates):\n",
        "    # Select data for the current patient\n",
        "        patient_data = eeg_data[i]\n",
        "\n",
        "    # Create MNE Info object\n",
        "        info = mne.create_info(ch_names=channel_names, sfreq=sampling_rate, ch_types=channel_types)\n",
        "\n",
        "    # Set a standard 10-20 montage\n",
        "        montage = mne.channels.make_standard_montage('standard_1020')\n",
        "        info.set_montage(montage)\n",
        "\n",
        "    # Create Raw object\n",
        "        raw_data = mne.io.RawArray(patient_data.T, info)  # As MNE expects (channels, samples)\n",
        "\n",
        "    # Apply ICA\n",
        "        ica = ICA(n_components=15, random_state=97, max_iter='auto') # to reduce overfitting , n_components =15\n",
        "        ica.fit(raw_data)\n",
        "\n",
        "    # Plot ICA components (optional, to inspect visually)\n",
        "        ica.plot_components(title=f\"Patient {i+1} ICA components\")\n",
        "\n",
        "    # finding EOG artifacts\n",
        "        eog_indices, eog_scores = ica.find_bads_eog(raw_data, ch_name=['Fp1', 'Fp2','F7', 'F8'])\n",
        "        ica.exclude = eog_indices  # exclude components for EOG artifacts\n",
        "\n",
        "    # Store the ICA object for later use\n",
        "        ica_results.append(ica)\n",
        "\n",
        "    # Apply the ICA solution to the data to remove the artifacts\n",
        "        raw_corrected = ica.apply(raw_data.copy())\n",
        "\n",
        "        corrected_data_list.append(raw_corrected.get_data().T)  # Shape back to (n_samples, n_channels)\n",
        "    return ica_results, np.array(corrected_data_list)\n",
        "\n",
        "ica_control, corrected_control_data = implement_ICA(filtered_Control_signal)\n",
        "ica_adhd, corrected_adhd_data = implement_ICA(filtered_ADHD_signal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNsIDbeIMK8q"
      },
      "outputs": [],
      "source": [
        "corrected_control_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gZDMMGb7U1EK"
      },
      "outputs": [],
      "source": [
        "# removal of muscle artefacts\n",
        "\n",
        "def ICA_for_muscle_artefact_removal(eeg_data):\n",
        "    candidates, samples, channels = eeg_data.shape\n",
        "    sampling_rate = 128\n",
        "\n",
        "    # Define channel names and types\n",
        "    channel_names = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2','F7','F8','T7','T8','P7','P8','Fz','Cz','Pz']\n",
        "    channel_types = ['eeg'] * channels\n",
        "\n",
        "    ica_results = []\n",
        "    corrected_data_list = []\n",
        "\n",
        "    for i in range(candidates):\n",
        "    # Select data for the current patient\n",
        "        candidate_data = eeg_data[i]\n",
        "\n",
        "    # Create MNE Info object\n",
        "        info = mne.create_info(ch_names=channel_names, sfreq=sampling_rate, ch_types=channel_types)\n",
        "\n",
        "\n",
        "    # Create Raw object\n",
        "        raw_data = mne.io.RawArray(candidate_data.T, info)  # As MNE expects (channels, samples)\n",
        "    # Adding a standard montage\n",
        "        montage = mne.channels.make_standard_montage('standard_1020')\n",
        "        raw_data.set_montage(montage)\n",
        "        raw_data.filter(l_freq=1.0, h_freq=None) # highpass\n",
        "\n",
        "    # Apply ICA\n",
        "        ica = ICA(n_components=15, random_state=97, max_iter='auto') # to reduce overfitting , n_components =15\n",
        "        ica.fit(raw_data)\n",
        "\n",
        "        muscle_index, scores = ica.find_bads_muscle(raw_data)\n",
        "        ica.exclude = muscle_index  # exclude components for muscle artifacts\n",
        "        ica.plot_scores(scores, exclude=muscle_index)\n",
        "        print(f\"Automatically found muscle artifact ICA components: {muscle_index}\")\n",
        "\n",
        "    # Store the ICA object for later use\n",
        "        ica_results.append(ica)\n",
        "\n",
        "    # Apply the ICA solution to the data to remove the artifacts\n",
        "        raw_corrected = ica.apply(raw_data.copy())\n",
        "\n",
        "        corrected_data_list.append(raw_corrected.get_data().T)  # Shape back to (n_samples, n_channels)\n",
        "    return ica_results, np.array(corrected_data_list)\n",
        "\n",
        "ica_control1, corrected_control_data1 = ICA_for_muscle_artefact_removal(corrected_control_data)\n",
        "ica_adhd1, corrected_adhd_data1 = ICA_for_muscle_artefact_removal(corrected_adhd_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR-zEIiqfBgJ"
      },
      "outputs": [],
      "source": [
        "positive_freqs_adhd2, eeg_data_fft_positive_adhd2 = apply_fft(corrected_control_data1)\n",
        "positive_freqs_control2, eeg_data_fft_positive_control2 = apply_fft(corrected_adhd_data1)\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Control Data analysis in Frequency Domain')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Power')\n",
        "for i in range(eeg_data_fft_positive_control2.shape[0]):\n",
        "    for j in range(eeg_data_fft_positive_control2.shape[2]):\n",
        "        plt.plot(positive_freqs_control2, np.abs(eeg_data_fft_positive_control2[i,:,j]))\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.title('ADHD Data analysis in Frequency Domain')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Power')\n",
        "for i in range(eeg_data_fft_positive_adhd2.shape[0]):\n",
        "    for j in range(eeg_data_fft_positive_adhd2.shape[2]):\n",
        "        plt.plot(positive_freqs_adhd2, np.abs(eeg_data_fft_positive_adhd2[i,:,j]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL2zrs34U1Hi"
      },
      "outputs": [],
      "source": [
        "# creating label for ADHD data\n",
        "adhd_label = np.ones(corrected_adhd_data1.shape[0])\n",
        "print(adhd_label)\n",
        "#creating control label\n",
        "control_label = np.zeros(corrected_control_data1.shape[0])\n",
        "print(control_label.shape)\n",
        "#combining the label arrays\n",
        "combined_label_array = np.concatenate((adhd_label, control_label))\n",
        "print(combined_label_array.shape)\n",
        "print(combined_label_array)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_XBXa5laEL5"
      },
      "outputs": [],
      "source": [
        "corrected_adhd_data1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jWEbYEWU1LA"
      },
      "outputs": [],
      "source": [
        "# combining ADHD and control data arrays\n",
        "combined_data_array = np.concatenate((corrected_adhd_data1, corrected_control_data1), axis=0)\n",
        "print(combined_data_array.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BgRPcfM6P5N5"
      },
      "outputs": [],
      "source": [
        "#plotting eeg signals after preprocessing\n",
        "eeg_signal_plot(corrected_adhd_data1,channel_seq)\n",
        "eeg_signal_plot(corrected_control_data1,channel_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avzwX9rCsCX-"
      },
      "outputs": [],
      "source": [
        "!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gAOgOggsTxL"
      },
      "outputs": [],
      "source": [
        "import pywt\n",
        "def wavelet_artefact_removal(eeg_data, wavelet, level, threshold):\n",
        "    \"\"\"\n",
        "    Apply discrete wavelet transform to EEG data.\n",
        "\n",
        "    Returns:\n",
        "         EEG data without artefacts\n",
        "    \"\"\"\n",
        "# Process each channel for each patient\n",
        "    for candidate in range(eeg_data.shape[0]):\n",
        "        for channel in range(eeg_data.shape[2]):\n",
        "            # Extract the signal for the current patient and channel\n",
        "            signal = eeg_data[candidate, :, channel]\n",
        "\n",
        "            # Perform wavelet decomposition\n",
        "            coeffecients = pywt.wavedec(signal, wavelet, mode='symmetric',level=level)\n",
        "\n",
        "            # Apply soft thresholding to the detail coefficients (artifact removal)\n",
        "            coeffs_thresholded = [coeffecients[0]]  # Approximation coefficients\n",
        "            for i in range(1, len(coeffecients)):\n",
        "                coeffs_thresholded.append(pywt.threshold(coeffecients[i], threshold * np.max(coeffecients[i]), mode='hard'))\n",
        "\n",
        "            # Reconstruct the signal from the thresholded coefficients\n",
        "            no_artefacts_signal = pywt.waverec(coeffs_thresholded, wavelet)\n",
        "\n",
        "            # Store the denoised signal back into the array\n",
        "            eeg_data[candidate, :, channel] = no_artefacts_signal[:eeg_data.shape[1]]\n",
        "\n",
        "    return eeg_data\n",
        "\n",
        "# Apply wavelet denoising\n",
        "wavelet = 'db4'    # Daubechies wavelet\n",
        "level = 7         # Number of decomposition levels\n",
        "threshold = 0.5    # Denoising threshold\n",
        "\n",
        "no_artefact_ADHD_data = wavelet_artefact_removal(corrected_adhd_data1, wavelet, level, threshold)\n",
        "no_artefact_Control_data = wavelet_artefact_removal(corrected_control_data1, wavelet=wavelet, level=level, threshold=threshold)\n",
        "print(no_artefact_ADHD_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_patients_and_channels_data(original_eeg_data, denoised_eeg_data, candidates, channels):\n",
        "    \"\"\"\n",
        "    Plotting the original and denoised EEG signals for all patients and channels.\n",
        "    \"\"\"\n",
        "    # Set up the plot\n",
        "    figure, axes = plt.subplots(candidates, channels, figsize=(20, candidates * 2), sharex=True, sharey=True)\n",
        "    figure.suptitle(\"Before vs After Denoised EEG\", fontsize=16)\n",
        "\n",
        "    # Iterates over patients and channels\n",
        "    for candidate_index in range(candidates):\n",
        "        for channel_index in range(channels):\n",
        "            ax = axes[candidate_index, channel_index]\n",
        "\n",
        "            # Extracts the signals for the current patient and channel\n",
        "            before_wavelet= original_eeg_data[candidate_index, :, channel_index]\n",
        "            after_wavelet = denoised_eeg_data[candidate_index, :, channel_index]\n",
        "\n",
        "            # Plot original and denoised signals\n",
        "            ax.plot(before_wavelet, label='Original', alpha=0.7)\n",
        "            ax.plot(after_wavelet, label='Denoised', alpha=0.7, linestyle='--')\n",
        "\n",
        "            # Remove ticks for better readability\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "\n",
        "            # Add labels to the first row and column\n",
        "            if candidate_index == 0:\n",
        "                ax.set_title(f\"Ch {channel_index + 1}\")\n",
        "            if channel_index == 0:\n",
        "                ax.set_ylabel(f\"Patient {candidate_index + 1}\", rotation=0, labelpad=20)\n",
        "\n",
        "    # Add a single legend for the entire figure\n",
        "    handles, labels = axes[0, 0].get_legend_handles_labels()  # is a built-in method in the Matplotlib library\n",
        "    figure.legend(handles, labels, loc='upper center', fontsize=12, bbox_to_anchor=(0.5, 1.05), ncol=2)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 0.95, 0.98])  # Adjust layout for the title and legend\n",
        "    plt.show()\n",
        "\n",
        "candidates_adhd = no_artefact_ADHD_data.shape[0]\n",
        "channels = no_artefact_ADHD_data.shape[2]\n",
        "\n",
        "candidates_control = no_artefact_Control_data.shape[0]\n",
        "channels = no_artefact_Control_data.shape[2]\n",
        "# Plot the results for all patients and channels\n",
        "plot_patients_and_channels_data(corrected_adhd_data1, no_artefact_ADHD_data, candidates_adhd, channels)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vI5khu6OkptU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_patients_and_channels_data(corrected_control_data1, no_artefact_Control_data, candidates_control, channels)"
      ],
      "metadata": {
        "id": "4JZfos0ctSjy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywadPN1PspON"
      },
      "outputs": [],
      "source": [
        "# time domain analysis\n",
        "mean_vals = np.mean(no_artefact_ADHD_data, axis=1)\n",
        "variance_vals = np.var(no_artefact_ADHD_data, axis=1)\n",
        "rms_vals = np.sqrt(np.mean(no_artefact_ADHD_data**2, axis=1))\n",
        "std_dev_vals = np.std(no_artefact_ADHD_data, axis=1)\n",
        "\n",
        "channels = np.arange(1, 20)  # 19 channels\n",
        "\n",
        "# Create subplots\n",
        "figure, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
        "figure.suptitle(\"Time-Domain Metrics for All ADHD Patients\")\n",
        "\n",
        "# Plot metrics for all patients\n",
        "for patient_index in range(mean_vals.shape[0]):\n",
        "    # Mean values\n",
        "    axs[0, 0].plot(channels, mean_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[0, 0].set_title(\"Mean Values\")\n",
        "    axs[0, 0].set_xlabel(\"Channel\")\n",
        "    axs[0, 0].set_ylabel(\"Mean Amplitude\")\n",
        "\n",
        "    # Variance values\n",
        "    axs[0, 1].plot(channels, variance_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[0, 1].set_title(\"Variance Values\")\n",
        "    axs[0, 1].set_xlabel(\"Channel\")\n",
        "    axs[0, 1].set_ylabel(\"Variance\")\n",
        "\n",
        "    # RMS values\n",
        "    axs[1, 0].plot(channels, rms_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[1, 0].set_title(\"RMS Values\")\n",
        "    axs[1, 0].set_xlabel(\"Channel\")\n",
        "    axs[1, 0].set_ylabel(\"RMS Amplitude\")\n",
        "\n",
        "    # Standard deviation values\n",
        "    axs[1, 1].plot(channels, std_dev_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[1, 1].set_title(\"Standard Deviation Values\")\n",
        "    axs[1, 1].set_xlabel(\"Channel\")\n",
        "    axs[1, 1].set_ylabel(\"Standard Deviation\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6nxs82AP3se"
      },
      "outputs": [],
      "source": [
        "# time domain analysis\n",
        "mean_vals = np.mean(no_artefact_Control_data, axis=1)\n",
        "variance_vals = np.var(no_artefact_Control_data, axis=1)\n",
        "rms_vals = np.sqrt(np.mean(no_artefact_Control_data**2, axis=1))\n",
        "std_dev_vals = np.std(no_artefact_Control_data, axis=1)\n",
        "\n",
        "channels = np.arange(1, 20)  # 19 channels\n",
        "\n",
        "# Create subplots\n",
        "figure, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
        "figure.suptitle(\"Time-Domain Metrics for All Control Patients\")\n",
        "\n",
        "# Plot metrics for all patients\n",
        "for patient_index in range(mean_vals.shape[0]):\n",
        "    # Mean values\n",
        "    axs[0, 0].plot(channels, mean_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[0, 0].set_title(\"Mean Values\")\n",
        "    axs[0, 0].set_xlabel(\"Channel\")\n",
        "    axs[0, 0].set_ylabel(\"Mean Amplitude\")\n",
        "\n",
        "    # Variance values\n",
        "    axs[0, 1].plot(channels, variance_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[0, 1].set_title(\"Variance Values\")\n",
        "    axs[0, 1].set_xlabel(\"Channel\")\n",
        "    axs[0, 1].set_ylabel(\"Variance\")\n",
        "\n",
        "    # RMS values\n",
        "    axs[1, 0].plot(channels, rms_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[1, 0].set_title(\"RMS Values\")\n",
        "    axs[1, 0].set_xlabel(\"Channel\")\n",
        "    axs[1, 0].set_ylabel(\"RMS Amplitude\")\n",
        "\n",
        "    # Standard deviation values\n",
        "    axs[1, 1].plot(channels, std_dev_vals[patient_index, :], label=f\"Patient {patient_index+1}\", alpha=0.5)\n",
        "    axs[1, 1].set_title(\"Standard Deviation Values\")\n",
        "    axs[1, 1].set_xlabel(\"Channel\")\n",
        "    axs[1, 1].set_ylabel(\"Standard Deviation\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3GlIq_qfhLv0"
      },
      "outputs": [],
      "source": [
        "!pip install -U mne-connectivity\n",
        "!pip install spectral_connectivity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PUCi-i6bTfxs"
      },
      "outputs": [],
      "source": [
        "# connectivity analysis\n",
        "from mne_connectivity import spectral_connectivity_epochs\n",
        "\n",
        "def functional_connectivity_for_eeg(eeg_data, sfreq):\n",
        "    \"\"\"\n",
        "    Compute functional connectivity metrics (correlation and coherence) for all patients and frequency bands.\n",
        "    Returns 'result' a dict\n",
        "    \"\"\"\n",
        "    # Frequency bands\n",
        "    bands = {\n",
        "        \"Delta\": (0.5, 4),\n",
        "        \"Theta\": (4, 8),\n",
        "        \"Alpha\": (8, 13),\n",
        "        \"Beta\": (13, 30),\n",
        "        \"Gamma\": (30, 50)\n",
        "    }\n",
        "\n",
        "    candidates, samples, channels = eeg_data.shape\n",
        "    result = {}\n",
        "\n",
        "    # Define channel names and types\n",
        "    channel_names = [\n",
        "        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
        "        'F7', 'F8', 'T7', 'T8', 'P7', 'P8', 'Fz', 'Cz', 'Pz'\n",
        "    ]\n",
        "    channel_types = ['eeg'] * channels\n",
        "\n",
        "    for candidate in range(candidates):\n",
        "        candidate_results = {}\n",
        "        eeg_individual_data = eeg_data[candidate].T  # Shape: (channels, samples)\n",
        "\n",
        "        # Create an MNE Raw object\n",
        "        info = mne.create_info(ch_names=channel_names, sfreq=sfreq, ch_types=channel_types)\n",
        "        raw_data = mne.io.RawArray(eeg_individual_data, info)\n",
        "\n",
        "        # Compute Correlation Matrix\n",
        "        correlation_matrix = np.corrcoef(eeg_individual_data)\n",
        "        candidate_results[\"Correlation\"] = correlation_matrix\n",
        "\n",
        "        # Compute Coherence for each frequency band\n",
        "        band_results = {}\n",
        "        for band, (fmin, fmax) in bands.items():\n",
        "            # Spectral connectivity calculation\n",
        "            con = spectral_connectivity_epochs(\n",
        "                np.expand_dims(raw_data.get_data(), axis=0),  # Add an epoch dimension\n",
        "                sfreq=sfreq,\n",
        "                method=\"coh\",\n",
        "                mode=\"multitaper\",\n",
        "                fmin=fmin,\n",
        "                fmax=fmax,\n",
        "                faverage=True,\n",
        "                verbose=False\n",
        "            )\n",
        "            coherence_matrix = con.get_data(output=\"dense\")[:, :, 0]  # Extract coherence values\n",
        "            band_results[band] = coherence_matrix\n",
        "\n",
        "        candidate_results[\"Coherence\"] = band_results\n",
        "        result[f\"Patient_{candidate}\"] = candidate_results\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "sfreq = 128\n",
        "# Computing functional connectivity\n",
        "results_adhd = functional_connectivity_for_eeg(no_artefact_ADHD_data, sfreq=sfreq)\n",
        "results_control = functional_connectivity_for_eeg(no_artefact_Control_data, sfreq=sfreq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "giW5MNCRTf01"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def plot_coherence_matrices(results, bands):\n",
        "    \"\"\"\n",
        "    Plots the coherence matrices for each patient and each frequency band.\n",
        "    Parameters:\n",
        "    - results: dict\n",
        "        The dictionary contains the computed coherence matrices for each patient and frequency band.\n",
        "    - bands: dict\n",
        "        The dictionary containing the frequency bands.\n",
        "    \"\"\"\n",
        "    # Iterate over all the patients\n",
        "    for patient_id, patient_results in results.items():\n",
        "        band_results = patient_results[\"Coherence\"]\n",
        "\n",
        "        # plot for each frequency band\n",
        "        figure, axes = plt.subplots(1, len(bands), figsize=(15, 5))\n",
        "\n",
        "        # If only one band, axes will be a single object, so make sure it's a list\n",
        "        if len(bands) == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        # Loop through each frequency band\n",
        "        for i, (band, _) in enumerate(bands.items()):\n",
        "            # Get the coherence matrix for the current band\n",
        "            coherence_matrix = band_results[band]\n",
        "\n",
        "            # Plot the coherence matrix as a heatmap\n",
        "            sns.heatmap(coherence_matrix, ax=axes[i], cmap=\"coolwarm\", annot=False, xticklabels=False, yticklabels=False)\n",
        "            axes[i].set_title(f\"{band} Band\")\n",
        "            axes[i].set_xlabel('Channels')\n",
        "            axes[i].set_ylabel('Channels')\n",
        "\n",
        "        # Set a title for the whole figure\n",
        "        figure.suptitle(f\"Coherence Matrices for Patient {patient_id}\", fontsize=16)\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # This is to adjust layout to avoid title overlap\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "#results_adhd is the dictionary containing the coherence results for all patients\n",
        "bands = {\n",
        "        \"Delta\": (0.5, 4),\n",
        "        \"Theta\": (4, 8),\n",
        "        \"Alpha\": (8, 13),\n",
        "        \"Beta\":  (13, 30),\n",
        "        \"Gamma\": (30, 50)\n",
        "    }\n",
        "plot_coherence_matrices(results_adhd, bands)\n",
        "plot_coherence_matrices(results_control, bands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y5HAiT0bTf3-"
      },
      "outputs": [],
      "source": [
        "# PSD Analysis\n",
        "from mne.time_frequency import psd_array_welch\n",
        "\n",
        "def spectral_density_analysis(eeg_data, sfreq, plot=True):\n",
        "    \"\"\"\n",
        "    This function is for spectral density analysis and plot the results using MNE.\n",
        "    This function returns psds an ndarray\n",
        "    Power spectral density values of shape (channels, freqs).\n",
        "    \"\"\"\n",
        "    candidates, samples, channels = eeg_data.shape\n",
        "    fmin=0.1\n",
        "    fmax=50.0\n",
        "\n",
        "    # Initialize MNE Info object\n",
        "       # Define channel names and types\n",
        "    channel_names = [\n",
        "        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
        "        'F7', 'F8', 'T7', 'T8', 'P7', 'P8', 'Fz', 'Cz', 'Pz']\n",
        "    channel_types = ['eeg'] * channels\n",
        "    info = mne.create_info(ch_names=channel_names, sfreq=sfreq, ch_types=channel_types)\n",
        "\n",
        "    # Create MNE RawArray for each trial and compute PSD\n",
        "    psds_list = []\n",
        "    for trial in eeg_data:\n",
        "        raw_data = mne.io.RawArray(trial.T, info, verbose=False)\n",
        "        trial_psd, freqs = psd_array_welch(trial.T, sfreq=sfreq, fmin=fmin, fmax=fmax, n_fft=1024)\n",
        "        psds_list.append(trial_psd)\n",
        "\n",
        "    # Average PSD across trials\n",
        "    psds_list = np.mean(psds_list, axis=0)  # Shape: (channels, freqs)\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for ch_index, ch_name in enumerate(channel_names):\n",
        "            plt.plot(freqs, psds_list[ch_index], label=ch_name)\n",
        "        plt.xlabel('Frequency (Hz)')\n",
        "        plt.ylabel('Power Spectral Density (dB)')\n",
        "        plt.title('Average Power Spectral Density Across Trials')\n",
        "        plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
        "        plt.grid()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return psds_list, freqs\n",
        "\n",
        "\n",
        "sfreq = 128\n",
        "psds_adhd, freqs_adhd = spectral_density_analysis(no_artefact_ADHD_data, sfreq)\n",
        "#psds_control, freqs_control = spectral_density_analysis(no_artefact_Control_data, sfreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RW3vjyszTf61"
      },
      "outputs": [],
      "source": [
        "psds_control, freqs_control = spectral_density_analysis(no_artefact_Control_data, sfreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uBHe_HrUB5_P"
      },
      "outputs": [],
      "source": [
        "# EEG data is loaded as eeg_data with shape (n_trials, n_samples, n_channels)\n",
        "# sfreq is the sampling frequency\n",
        "def compute_psd_features(eeg_data, sfreq, fmin=0.1, fmax=50.0):\n",
        "    n_trials, n_samples, n_channels = eeg_data.shape\n",
        "    fmin= 0.1\n",
        "    fmax= 50.0\n",
        "\n",
        "    # Define channel names and types\n",
        "    channel_names = [\n",
        "        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
        "        'F7', 'F8', 'T7', 'T8', 'P7', 'P8', 'Fz', 'Cz', 'Pz']\n",
        "    channel_types = ['eeg'] * n_channels\n",
        "    # Initialize MNE Info object\n",
        "    info = mne.create_info(ch_names=channel_names, sfreq=sfreq, ch_types=channel_types)\n",
        "\n",
        "    # Creating MNE RawArray for each trial and computing PSD\n",
        "    psds_list = []\n",
        "    for trial in eeg_data:\n",
        "        raw_data = mne.io.RawArray(trial.T, info, verbose=False)\n",
        "        trial_psds, freqs = psd_array_welch(trial.T, sfreq=sfreq, fmin=fmin, fmax=fmax, n_fft=1024)\n",
        "        psds_list.append(trial_psds)\n",
        "    return np.array(psds_list), freqs\n",
        "\n",
        "\n",
        "sfreq = 128\n",
        "psd_features_control, freqs_ontrol = compute_psd_features(no_artefact_Control_data, sfreq)\n",
        "psd_features_control.shape\n",
        "psd_features_adhd, freqs_adhd = compute_psd_features(no_artefact_ADHD_data, sfreq)\n",
        "psd_features_adhd.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Cb_5QrwfCZFk"
      },
      "outputs": [],
      "source": [
        "\n",
        "combined_data_array1 = np.concatenate((psd_features_adhd, psd_features_control), axis=0)\n",
        "print(combined_data_array1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Pg9oQCscEdaS"
      },
      "outputs": [],
      "source": [
        "# creating label for ADHD data\n",
        "adhd_label = np.ones(corrected_adhd_data1.shape[0])\n",
        "print(adhd_label)\n",
        "#creating control label\n",
        "control_label = np.zeros(corrected_control_data1.shape[0])\n",
        "print(control_label.shape)\n",
        "#combining the label arrays\n",
        "combined_label_array = np.concatenate((adhd_label, control_label))\n",
        "print(combined_label_array.shape)\n",
        "print(combined_label_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-cNA4f6m8ne"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# Split data into train and test\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(combined_data_array1, combined_label_array, test_size=0.2, random_state=105)\n",
        "\n",
        "# One-hot encode the labels for classification\n",
        "ytrain = to_categorical(ytrain, num_classes=2)\n",
        "ytest = to_categorical(ytest, num_classes=2)\n",
        "\n",
        "xtrain.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubTU5WM8m81s"
      },
      "outputs": [],
      "source": [
        "ytrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bdYEGOrm843"
      },
      "outputs": [],
      "source": [
        "xtrain_flattened = xtrain.reshape(xtrain.shape[0], -1)\n",
        "xtest_flattened = xtest.reshape(xtest.shape[0], -1)\n",
        "\n",
        "# For SVM, we need a single label per sample, so we use one of the columns\n",
        "ytrain_flattened = ytrain[:, 0]\n",
        "ytest_flattened = ytest[:, 0]\n",
        "\n",
        "training_errors = []\n",
        "validation_errors = []\n",
        "\n",
        "\n",
        "# Initialize and train the SVM model\n",
        "model = SVC(kernel='linear', C=1, random_state=24)\n",
        "model.fit(xtrain_flattened, ytrain_flattened)\n",
        "# predictions\n",
        "ytrain_pred = model.predict(xtrain_flattened)\n",
        "ypred = model.predict(xtest_flattened)\n",
        "# Evaluate the model\n",
        "training_accuracy = accuracy_score(ytrain_flattened, ytrain_pred)\n",
        "accuracy = accuracy_score(ytest_flattened, ypred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "# Calculate errors (1 - accuracy)\n",
        "training_error = 1 - training_accuracy\n",
        "validation_error = 1 - accuracy\n",
        "print(f\"Validation Error: {validation_error:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the bar plot\n",
        "types_of_error = ['Training Error', 'Validation Error']\n",
        "errors = [training_error, validation_error]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(types_of_error, errors, color=['blue', 'red'], alpha=0.7)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Training vs Validation Error for SVM\", fontsize=14)\n",
        "plt.ylabel(\"Error\", fontsize=12)\n",
        "plt.ylim(0, 1)  # Assuming errors are in the range [0, 1]\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BoTQbuRf3Qy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the bar plot\n",
        "accuracies_type = ['Training Accuracy', 'Validation Accuracy']\n",
        "accuracy = [training_accuracy, accuracy]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(accuracies_type, accuracy, color=['blue', 'red'], alpha=0.7)\n",
        "\n",
        "plt.title(\"Training vs Validation Accuracy of SVM\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FTSOrph93k9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scaling the features\n",
        "scaler = StandardScaler()\n",
        "xtrain_flattened_scaled = scaler.fit_transform(xtrain_flattened)\n",
        "xtest_flattened_scaled = scaler.transform(xtest_flattened)\n",
        "\n",
        "#hyper parameter tuning\n",
        "params = {\n",
        "    'C': [0.5, 1, 2, 3, 4],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with 5-fold cross-validation\n",
        "gscv = GridSearchCV(SVC(), params, cv=5, n_jobs=-1)\n",
        "gscv.fit(xtrain_flattened_scaled, ytrain_flattened)\n",
        "\n",
        "# Get the best parameters\n",
        "print(f\"Best parameters: {gscv.best_params_}\")\n",
        "print(f\"Best cross-validation score: {gscv.best_score_:.2f}\")"
      ],
      "metadata": {
        "id": "15mPUsg4yj-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialising and train the SVM model with cross-validation\n",
        "model_gscv = SVC(kernel='rbf', C=1, gamma='auto')\n",
        "model_gscv.fit(xtrain_flattened_scaled, ytrain_flattened)\n",
        "\n",
        "# predictions\n",
        "ytrain_pred_gscv = model_gscv.predict(xtrain_flattened_scaled)\n",
        "ypred_gscv = model_gscv.predict(xtest_flattened_scaled)\n",
        "\n",
        "# Evaluation of the model\n",
        "training_accuracy_gscv = accuracy_score(ytrain_flattened, ytrain_pred_gscv)\n",
        "val_accuracy_gscv = accuracy_score(ytest_flattened, ypred_gscv)\n",
        "print(f\"Accuracy: {val_accuracy_gscv:.2f}\")\n",
        "training_error_gscv = 1 - training_accuracy_gscv\n",
        "validation_error_gscv = 1 - val_accuracy_gscv\n",
        "print(f\"Training Error: {training_error_gscv:.2f}\")\n",
        "print(f\"Validation Error: {validation_error_gscv:.2f}\")\n"
      ],
      "metadata": {
        "id": "-CO0wssHqFty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the bar plot\n",
        "types_of_error_gscv = ['Training Error', 'Validation Error']\n",
        "errors_gscv = [training_error_gscv, validation_error_gscv]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(types_of_error_gscv, errors_gscv, color=['blue', 'red'], alpha=0.7)\n",
        "\n",
        "plt.title(\"Training vs Validation Error for SVM after Hyper-Parameter Tuning\", fontsize=14)\n",
        "plt.ylabel(\"Error\", fontsize=12)\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Id-9feAPqGO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the bar plot\n",
        "accuracies_type_gscv = ['Training Accuracy', 'Validation Accuracy']\n",
        "accuracy_gscv = [training_accuracy_gscv, val_accuracy_gscv]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(accuracies_type_gscv, accuracy_gscv, color=['blue', 'red'], alpha=0.7)\n",
        "\n",
        "plt.title(\"Training vs Validation Accuracy of SVM after Hyper-Parameter Tuning\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IucdFyDBqGZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "# Initialize and train the XGBoost model\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=102)\n",
        "model_xgb.fit(xtrain_flattened, ytrain_flattened)\n",
        "\n",
        "# Make predictions\n",
        "ytrain_pred_xgb = model_xgb.predict(xtrain_flattened)\n",
        "ypred_xgb = model_xgb.predict(xtest_flattened)\n",
        "\n",
        "# Evaluate the model\n",
        "training_accuracy_xgb = accuracy_score(ytrain_flattened, ytrain_pred_xgb)\n",
        "accuracy_xgb = accuracy_score(ytest_flattened, ypred_xgb)\n",
        "print(f\"Accuracy: {accuracy_xgb:.2f}\")\n",
        "\n",
        "# Calculate errors (1 - accuracy)\n",
        "training_error_xgb = 1 - training_accuracy_xgb\n",
        "validation_error_xgb = 1 - accuracy_xgb\n",
        "\n",
        "# Print errors\n",
        "print(f\"Training Error: {training_error_xgb:.2f}\")\n",
        "print(f\"Validation Error: {validation_error_xgb:.2f}\")"
      ],
      "metadata": {
        "id": "SfxPUMDaIakX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the bar plot\n",
        "types_of_error_xgb = ['Training Error', 'Validation Error']\n",
        "errors_xgb = [training_error_xgb, validation_error_xgb]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(types_of_error_xgb, errors_xgb, color=['blue', 'red'], alpha=0.7)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Training vs Validation Error for XG Boost\", fontsize=14)\n",
        "plt.ylabel(\"Error\", fontsize=12)\n",
        "plt.ylim(0, 1)  # Assuming errors are in the range [0, 1]\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TFeC5hz4Qf0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the bar plot\n",
        "accuracies_type_xgb = ['Training Accuracy', 'Validation Accuracy']\n",
        "val_accuracy_xgb = [training_accuracy_xgb, accuracy_xgb]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(accuracies_type_xgb, val_accuracy_xgb, color=['blue', 'red'], alpha=0.7)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Training vs Validation Accuracy of XG Boost\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.ylim(0, 1)  # Accuracies are in the range [0, 1]\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eWGJ3RalQgBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter tuning for XGBoost\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [25, 50, 75],\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "}\n",
        "\n",
        "# Initialising GridSearchCV with 5-fold cross-validation\n",
        "model_xgb = XGBClassifier(random_state=24, eval_metric='logloss')\n",
        "gscv_xgb = GridSearchCV(estimator=model_xgb, param_grid=param_grid_xgb, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the model to the training data\n",
        "gscv_xgb.fit(xtrain_flattened_scaled, ytrain_flattened)\n",
        "\n",
        "# Get the best parameters and the best model\n",
        "best_params = gscv_xgb.best_params_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pm7TQFww6DcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params)"
      ],
      "metadata": {
        "id": "t2mp59Qa6EXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize and train the XGBoost model\n",
        "model_xgb_best = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=102, max_depth=5, learning_rate=0.1,n_estimators=25)\n",
        "model_xgb_best.fit(xtrain_flattened, ytrain_flattened)\n",
        "\n",
        "# Make predictions\n",
        "ytrain_pred_xgb_best = model_xgb_best.predict(xtrain_flattened)\n",
        "ypred_xgb_best = model_xgb_best.predict(xtest_flattened)\n",
        "\n",
        "# Evaluate the model\n",
        "training_accuracy_xgb_best = accuracy_score(ytrain_flattened, ytrain_pred_xgb_best)\n",
        "accuracy_xgb_best = accuracy_score(ytest_flattened, ypred_xgb_best)\n",
        "print(f\"Accuracy: {accuracy_xgb_best:.2f}\")\n",
        "\n",
        "# Calculate errors (1 - accuracy)\n",
        "training_error_xgb_best = 1 - training_accuracy_xgb_best\n",
        "validation_error_xgb_best = 1 - accuracy_xgb_best\n",
        "\n",
        "# Print errors\n",
        "print(f\"Training Error: {training_error_xgb_best:.2f}\")\n",
        "print(f\"Validation Error: {validation_error_xgb_best:.2f}\")"
      ],
      "metadata": {
        "id": "rLBcV-2R6Env"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the bar plot\n",
        "accuracies_type_xgb_best = ['Training Accuracy', 'Validation Accuracy']\n",
        "val_accuracy_xgb_best = [training_accuracy_xgb_best, accuracy_xgb_best]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(accuracies_type_xgb_best, val_accuracy_xgb_best, color=['blue', 'red'], alpha=0.7)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Training vs Validation Accuracy of XG Boost after Tuning\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.ylim(0, 1)  # as Accuracies are in the range [0, 1]\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N7_GyWNNNToo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Reshaping PSD features for CNN (trials, channels, freqs, 1)\n",
        "combined_data_array1 = combined_data_array1.reshape(combined_data_array1.shape[0], combined_data_array1.shape[1], combined_data_array1.shape[2], 1)\n",
        "\n",
        "# Split data into train and test\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(combined_data_array1, combined_label_array, test_size=0.2, random_state=105)\n",
        "\n",
        "# One-hot encode the labels for classification\n",
        "ytrain = to_categorical(ytrain, num_classes=2)\n",
        "ytest = to_categorical(ytest, num_classes=2)\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# First Conv2D layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=(combined_data_array1.shape[1], combined_data_array1.shape[2], 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# Second Conv2D layer\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# Third Conv2D layer with strided convolution\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', strides=2, padding='valid'))\n",
        "\n",
        "# Flatten the output of the last Conv2D layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=10, batch_size=32)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "om8cjPgDNT1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.plot(range(10), history.history['loss'], label='loss')\n",
        "plt.plot(range(10), history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k2tnoBWLORwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(range(10), history.history['accuracy'], label='accuracy')\n",
        "plt.plot(range(10), history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zU0ChPMeOR19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QOAEiMFnprYI"
      },
      "outputs": [],
      "source": [
        "# after tuning the model\n",
        "model = Sequential()\n",
        "\n",
        "# First Conv2D layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=(combined_data_array1.shape[1], combined_data_array1.shape[2], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# Second Conv2D layer\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# Third Conv2D layer with strided convolution\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', strides=2, padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Flatten last Conv2D layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=10, batch_size=32)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWaIGhcjprpA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(range(10), history.history['loss'], label='loss')\n",
        "plt.plot(range(10), history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEJSVyYCpr37"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(range(10), history.history['accuracy'], label='accuracy')\n",
        "plt.plot(range(10), history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bmj3VGHruyuI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA1AdVE_DPF9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaDhBL_SDPI_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK3tsQmUDPL6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "athNVrGPDPOp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuTlMJJdDPRv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJLMGizEDPUX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lOs8JSfDPXO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1nn_8JoDPam"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUhH1imKhQAW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jzgQOdCcrIHs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6d7iU50jRWE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3NPlIEsrIQo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lNHN7nmPQel"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx4bJD-ZPQhV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK7e6EeRPQm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fMGsZPNPQpd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "102YhYOEPQsE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg2sa1WHPQur"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUt6uO2dPQxT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qdae7buPQ0E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpVSCaQLPQ2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9k9vIVQPQ5N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xxw22vwPQ79"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJOd4fVgPRBi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSFOawd-PREK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjzcILP0PRGq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8r_9culPRJi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzJ_3aX4PRMb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4d4Jko8PRPR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOe1FqbQPRSJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwzo9ky7PRVF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpIA-JY_PRYJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_vI5EsUPRa5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1M3FSh8PRdh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCu18Dh0PRgB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8zjLOaTPRjg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}